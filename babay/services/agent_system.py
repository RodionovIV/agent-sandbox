from langchain.chat_models import ChatOpenAI\nfrom langchain.agents import create_react_agent\nfrom langchain.memory import MemorySaver\nfrom langchain.schema.messages import HumanMessage\n\nclass AgentSystem:\n    def __init__(self):\n        self.llm = ChatOpenAI(\n            model="gpt-3.5-turbo",\n            temperature=0.3,\n            max_tokens=8192,\n            streaming=False\n        )\n        self.functions = []\n        self.llm_with_functions = self.llm.bind_tools(self.functions)\n        self.agent_executor = create_react_agent(self.llm_with_functions, self.functions, checkpointer=MemorySaver())\n\n    def process(self, query: str) -> str:\n        message = {"messages": [HumanMessage(content=query)]}\n        result = self.agent_executor.invoke(message)\n        return result["result"]