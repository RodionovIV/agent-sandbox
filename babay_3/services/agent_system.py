\nfrom langchain_gigachat.chat_models import GigaChat\nfrom langchain_gigachat.tools.giga_tool import giga_tool\nfrom langchain.schema import HumanMessage\nfrom langgraph.prebuilt import create_react_agent\nfrom langgraph.checkpoint.memory import MemorySaver\n\nclass AgentSystem:\n    def __init__(self):\n        llm = GigaChat(\n            model="GigaChat-2-Max",\n            verify_ssl_certs=False,\n            profanity_check=False,\n            streaming=False,\n            max_tokens=8192,\n            temperature=0.3,\n            repetition_penalty=1.01,\n            timeout=60\n        )\n        functions = []\n        llm_with_functions = llm.bind_tools(functions)\n        self.agent_executor = create_react_agent(llm_with_functions, functions, checkpointer=MemorySaver())\n\n    def process(self, query: str) -> str:\n        message = {"messages": [HumanMessage(content=query)]}\n        result = self.agent_executor.invoke(message)\n        return result["result"]\n